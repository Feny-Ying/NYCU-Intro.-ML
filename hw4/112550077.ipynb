{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "下載資料用，如果已經下載好可以不執行"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xSruV9kh7IE",
        "outputId": "a8f03f75-c8f9-441d-f4e4-2a3bf7f93bd4"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jb0PUvS7h7BA"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/drive/MyDrive/dataset.zip\"  # 你的 zip 路徑\n",
        "extract_path = \"/content/data\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "安裝函式庫"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRDhMrojhnyl",
        "outputId": "fedf71ba-e09a-420b-d110-83060ccb30c9"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install pillow\n",
        "!pip install pandas\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ92OPNMhnql"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torchvision import models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "處理Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqGe13xRhp_r"
      },
      "outputs": [],
      "source": [
        "# --- Custom Dataset for unlabeled/test ---\n",
        "class ImageFolderWithoutLabels(Dataset):\n",
        "    def __init__(self, root, transform=None, extensions=(\"jpg\",\"jpeg\",\"png\")):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.extensions = extensions\n",
        "\n",
        "        # 找所有符合副檔名的檔案\n",
        "        self.images = [\n",
        "            os.path.join(root, fname) for fname in os.listdir(root)\n",
        "            if fname.lower().endswith(self.extensions)\n",
        "        ]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, img_path  # 回傳圖片和路徑，方便之後保存結果\n",
        "\n",
        "# --- 主函數 ---\n",
        "def get_loaders(root=\"./data/data\", batch_size=32, valid_ratio=0.1):\n",
        "\n",
        "    train_dir = os.path.join(root, \"train\")\n",
        "    test_dir  = os.path.join(root, \"test\")\n",
        "    unlabeled_dir = os.path.join(root, \"unlabeled\")\n",
        "\n",
        "    # ---------- Transforms ----------\n",
        "    train_tf = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),  # 可留可不留\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                            [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    eval_tf = transforms.Compose([\n",
        "        transforms.Resize((224,224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485,0.456,0.406],\n",
        "                             [0.229,0.224,0.225])\n",
        "    ])\n",
        "\n",
        "    # ---------- Train/Valid ----------\n",
        "    full_train = datasets.ImageFolder(train_dir, transform=train_tf)\n",
        "    total = len(full_train)\n",
        "    valid_len = int(total * valid_ratio)\n",
        "    train_len = total - valid_len\n",
        "    train_ds, valid_ds = random_split(full_train, [train_len, valid_len])\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # ---------- Test ----------\n",
        "    test_ds = ImageFolderWithoutLabels(test_dir, transform=eval_tf)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # ---------- Unlabeled ----------\n",
        "    unlabeled_ds = ImageFolderWithoutLabels(unlabeled_dir, transform=eval_tf)\n",
        "    unlabeled_loader = DataLoader(unlabeled_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader, unlabeled_loader\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "正式訓練\n",
        "資料必須放在指定位置\n",
        "    data_root = \"your data root direct\"\n",
        "    save_path = \"your model path\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S70UqP3Vhp2h",
        "outputId": "98e576ce-8c74-43f4-e13a-fd517333e348"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # ------------------ Config ------------------\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    num_epochs = 8\n",
        "    batch_size = 32\n",
        "    learning_rate = 0.01\n",
        "    num_classes = 2\n",
        "    data_root = \"/content/data/data\"\n",
        "    save_path = \"best_model_ef5.pth\"\n",
        "\n",
        "    # ------------------ Data ------------------\n",
        "    train_loader, valid_loader, test_loader, _ = get_loaders(\n",
        "        root=data_root,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "\n",
        "    # ------------------ Model ------------------\n",
        "    model = models.efficientnet_b7(\n",
        "    weights=models.EfficientNet_B7_Weights.IMAGENET1K_V1\n",
        "    )\n",
        "    in_features = model.classifier[1].in_features\n",
        "    model.classifier[1] = nn.Linear(in_features, num_classes)\n",
        "    model = model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(\n",
        "        model.parameters(),\n",
        "        lr=learning_rate,\n",
        "        momentum=0.9,\n",
        "        weight_decay=1e-3\n",
        "    )\n",
        "\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer,\n",
        "        T_max=num_epochs,\n",
        "        eta_min=1e-4  # 最小 lr\n",
        "    )\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # model.load_state_dict(torch.load(save_path))\n",
        "    # ------------------ Training ------------------\n",
        "    for epoch in range(num_epochs):\n",
        "        print(\"Model device:\", next(model.parameters()).device)\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train]\", ncols=100)\n",
        "        for images, labels in loop:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            loop.set_postfix(loss=loss.item())\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        scheduler.step()  # learning rate decay\n",
        "        # ------------------ Validation ------------------\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        loop_val = tqdm(valid_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Valid]\", ncols=100)\n",
        "        with torch.no_grad():\n",
        "            for images, labels in loop_val:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                val_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                loop_val.set_postfix(val_loss=loss.item())\n",
        "        avg_val_loss = val_loss / len(valid_loader)\n",
        "        accuracy = 100 * correct / total\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f} \"\n",
        "              f\"Valid Loss: {avg_val_loss:.4f} \"\n",
        "              f\"Valid Acc: {accuracy:.2f}%\")\n",
        "\n",
        "        if accuracy > best_acc:\n",
        "            best_acc = accuracy\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "\n",
        "    # ------------------ Test Prediction ------------------\n",
        "    print(\"Loading best model for test prediction...\")\n",
        "    model.load_state_dict(torch.load(save_path))\n",
        "    model.eval()\n",
        "    preds_list = []\n",
        "    image_paths = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        loop_test = tqdm(test_loader, desc=\"Predicting Test\", ncols=100)\n",
        "        for images, paths in loop_test:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            probs = torch.softmax(outputs, dim=1)[:,1]\n",
        "            preds = (probs <= 0.5).int().cpu().tolist()\n",
        "            preds_list.extend(preds)\n",
        "            image_paths.extend(paths)\n",
        "\n",
        "    # 去掉副檔名\n",
        "    filenames = [os.path.splitext(os.path.basename(p))[0] for p in image_paths]\n",
        "    submission = pd.DataFrame({\"filename\": filenames, \"label\": preds_list})\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    print(\"Submission file saved as submission.csv\")\n",
        "\n",
        "# ------------------ Entry Point ------------------\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
